{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "novelSet_path:  c:\\Users\\kimbo\\code\\insight_text_game\\translation\\..\\dataset\\visual-novels\\Parsed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_path = os.getcwd()\n",
    "dataset_path = os.path.join(current_path,\"..\\\\dataset\")\n",
    "    \n",
    "novelSet_path = os.path.join(dataset_path, \"visual-novels\\\\Parsed\")\n",
    "save_translation_novelJson_path = os.path.join(dataset_path, \"visual-novels-json-ko\")\n",
    "save_translation_novelTxt_path = os.path.join(dataset_path, \"visual-novels-txt-ko\")\n",
    "\n",
    "print(\"novelSet_path: \", novelSet_path)\n",
    "\n",
    "novel_list = os.listdir(novelSet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(_path):\n",
    "    if not os.path.exists(_path):\n",
    "        os.makedirs(_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_folder(dataset_path)\n",
    "create_folder(save_translation_novelJson_path)\n",
    "create_folder(save_translation_novelTxt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dict(object):\n",
    "    def __init__(self, name):\n",
    "        self._name = name\n",
    "\n",
    "    def __str__(self):\n",
    "        return self._name\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"'\"+str(self._name)+\"'\"\n",
    "\n",
    "class Gmark:\n",
    "    def __init__(self):\n",
    "        self.sig=False\n",
    "        self.cnt=0\n",
    "        self.idx=0\n",
    "        self.translation_cnt=0\n",
    "        self.json_dict=[]\n",
    "        self.novel_title=\"\"\n",
    "    \n",
    "    def add_cnt(self):\n",
    "        self.cnt+=1\n",
    "    def add_idx(self):\n",
    "        self.idx+=1\n",
    "    def add_translation_cnt(self):\n",
    "        self.translation_cnt+=1\n",
    "        \n",
    "    def get_cnt(self):\n",
    "        return self.cnt\n",
    "    def get_idx(self):\n",
    "        return self.idx\n",
    "    def get_translation_cnt(self):\n",
    "        return self.translation_cnt \n",
    "\n",
    "    def reset_cnt(self):\n",
    "        self.cnt=0\n",
    "    def reset_idx(self):\n",
    "        self.idx=0\n",
    "\n",
    "    def set_sig_true(self):\n",
    "        self.sig=True\n",
    "    def set_sig_false(self):\n",
    "        self.sig=False\n",
    "    def get_sig(self):\n",
    "        return self.sig\n",
    "    \n",
    "    def reset_json_dict(self):\n",
    "        self.json_dict.clear()\n",
    "    def add_json_dict(self, name, content):\n",
    "        self.json_dict.append({name:content})\n",
    "    def get_json_dict(self):\n",
    "        return self.json_dict\n",
    "    def get_json_dict_len(self):\n",
    "        return len(self.json_dict)\n",
    "    \n",
    "    def set_novel_title(self, title):\n",
    "        self.novel_title=title\n",
    "    def get_novel_title(self):\n",
    "        return self.novel_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    "\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "\n",
    "def translation(sentence):\n",
    "    tokenizer.src_lang = \"en_XX\"\n",
    "    encoded_hi = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    generated_tokens = model.generate(\n",
    "        **encoded_hi,\n",
    "        forced_bos_token_id=tokenizer.lang_code_to_id[\"ko_KR\"]\n",
    "    )\n",
    "    result = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qeustion_marker(name, content, gmark):\n",
    "    if content == \"\":\n",
    "        return\n",
    "    try:\n",
    "        content.replace(\"<USER>\", \"<###>\")\n",
    "        content = translation(content)[0]\n",
    "        gmark.add_translation_cnt()\n",
    "        if gmark.get_translation_cnt() % 2 == 0:\n",
    "            print(\"translation_cnt: \", gmark.get_translation_cnt())\n",
    "            \n",
    "        if gmark.get_cnt()>3:\n",
    "            if gmark.get_sig() & ('?' in content):\n",
    "                gmark.set_sig_false()\n",
    "                \n",
    "            if gmark.get_sig():\n",
    "                gmark.set_sig_false()\n",
    "                gmark.reset_cnt()\n",
    "                gmark.add_json_dict('question', \"===============================\")\n",
    "                gmark.add_json_dict(name,content)\n",
    "                gmark.add_json_dict('answer', \"===============================\")\n",
    "                return\n",
    "            \n",
    "        if '?' in content[-1]:\n",
    "            gmark.add_json_dict(name, content)\n",
    "            gmark.add_cnt()\n",
    "            gmark.set_sig_true()\n",
    "        else:\n",
    "            gmark.add_json_dict(name, content)\n",
    "            gmark.set_sig_false()\n",
    "            gmark.add_cnt()\n",
    "    except:\n",
    "        print(\"qeustion_marker error: \", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainData():\n",
    "    def __init__(self):\n",
    "        self.text=\"\"\n",
    "        self.trainSet=[]\n",
    "        self.input_novel=[]\n",
    "        self.answer=[]\n",
    "        self.output_novel=[]\n",
    "        self.train={}\n",
    "        self.q=False\n",
    "        self.a=False\n",
    "        \n",
    "    def set_q(self, boolean):\n",
    "        self.q=boolean\n",
    "    def set_a(self, boolean):\n",
    "        self.a=boolean\n",
    "        \n",
    "    def get_q(self):\n",
    "        return self.q\n",
    "    def get_a(self):\n",
    "        return self.a\n",
    "    \n",
    "    def add_value(self, tag, name, content):\n",
    "        if tag ==\"input_novel\":\n",
    "            self.input_novel.append({name:content})\n",
    "        elif tag ==\"answer\":\n",
    "            self.answer.append({name:content})\n",
    "        elif tag ==\"output_novel\":\n",
    "            self.output_novel.append({name:content})\n",
    "        elif tag == \"train\":\n",
    "            self.train[name] = content.copy()\n",
    "        elif tag == \"trainSet\":\n",
    "            self.trainSet.append(content.copy())\n",
    "        else:\n",
    "            print(\"No such key exist.\")\n",
    "    \n",
    "    def reset_value(self, name):\n",
    "        if name == \"input_novel\":\n",
    "            self.input_novel.clear()\n",
    "        elif name == \"answer\":\n",
    "            self.answer.clear()\n",
    "        elif name == \"output_novel\":\n",
    "            self.output_novel.clear()\n",
    "        elif name == \"train\":\n",
    "            self.train.clear()\n",
    "            \n",
    "    def get_value(self, name):\n",
    "        if name ==\"input_novel\":\n",
    "            return self.input_novel\n",
    "        elif name ==\"answer\":\n",
    "            return self.answer\n",
    "        elif name ==\"output_novel\":\n",
    "            return self.output_novel\n",
    "        elif name ==\"train\":\n",
    "            return self.train\n",
    "        elif name ==\"trainSet\":\n",
    "            return self.trainSet\n",
    "        else:\n",
    "            print(\"No such key exist.\")\n",
    "            \n",
    "    def change_trainSet(self):\n",
    "        self.input_novel = self.output_novel.copy()\n",
    "        self.reset_value('answer')\n",
    "        self.reset_value('output_novel')\n",
    "        self.reset_value('train')\n",
    "        \n",
    "    def set_token_word(self, word):\n",
    "        self.text+= f\"[{word}]\\n\"\n",
    "        \n",
    "    def set_dict(self, dict):\n",
    "        for i in dict:\n",
    "            for key, value in i.items():\n",
    "                self.text+= f\"{key}: {value}\\n\"\n",
    "    def get_text(self):\n",
    "        return self.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion_to_trainData(gmark):\n",
    "    def save_value():\n",
    "        train_data.add_value('train', 'input_novel', train_data.get_value('input_novel'))\n",
    "        train_data.set_token_word(\"input_novel\")\n",
    "        train_data.set_dict(train_data.get_value('input_novel'))\n",
    "        train_data.add_value('train', 'answer', train_data.get_value('answer'))\n",
    "        train_data.set_token_word(\"answer\")\n",
    "        train_data.set_dict(train_data.get_value('answer'))\n",
    "        train_data.add_value('train', 'output_novel', train_data.get_value('output_novel'))\n",
    "        train_data.set_token_word(\"output_novel\")\n",
    "        train_data.set_dict(train_data.get_value('output_novel'))\n",
    "        train_data.add_value('trainSet', 'train', train_data.get_value('train'))\n",
    "    \n",
    "    qmark_data = gmark.get_json_dict()\n",
    "    q=0\n",
    "    train_data = TrainData()\n",
    "    for qmark_data in gmark.get_json_dict():\n",
    "        for name, value in qmark_data.items():\n",
    "            if(str(name) == \"question\"):\n",
    "                train_data.set_q(True)\n",
    "                q+=1\n",
    "                if(q!=1):\n",
    "                    save_value()\n",
    "                    \n",
    "                    train_data.change_trainSet()\n",
    "                    train_data.set_a(False)\n",
    "                continue\n",
    "            if(str(name) == \"answer\"):\n",
    "                train_data.set_a(True)\n",
    "                continue\n",
    "                    \n",
    "            if not train_data.get_q() and not train_data.get_a():\n",
    "                train_data.add_value('input_novel', name, value)\n",
    "            elif train_data.get_q() and not train_data.get_a():\n",
    "                train_data.add_value('answer', name, value)\n",
    "            elif train_data.get_q() and train_data.get_a():\n",
    "                train_data.add_value('output_novel', name, value)\n",
    "            else:\n",
    "                print(\"Error: No matching question or answer found.\")\n",
    "    \n",
    "    if train_data.get_value('input_novel'):\n",
    "        save_value()\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "case_1 = ['A Clockwork Ley-Line - The Borderline of Dusk']\n",
    "    #\"TO:~ 로 시작하는 편지 존재\n",
    "case_2 = ['AIR']\n",
    "    #나레이션 태그 없음, *감탄사 존재\n",
    "case_3 = ['Amatarasu Riddle Star', 'Maitetsu']\n",
    "    #**~** 안의 내용 제거\n",
    "case_4 = ['Aokana - Four Rhythms Across the Blue']\n",
    "    #나레이션 태그 없음, <i></i> 형태의 강조 태그 존재\n",
    "case_5 = ['Blackberry Honey']\n",
    "    #대화문장 뒤 with dissolve존재, 대화 문장 내부에 {}, 언더바 존재\n",
    "case_6 = ['Chasing Tails A Promise In the Snow']\n",
    "    #{}, [] 존재\n",
    "case_7 = ['Comyu - Kuroi Ryuu to Yasashii Oukoku', 'Euphoria', 'Nurse Love Addiction', 'Nurse Love Syndrome', 'Sorcery Jokers','TheDevilOnGstring', 'CLANNAD']\n",
    "    #나레이션 태그 없음\n",
    "case_8 = ['Cross Worlds','Sisterly Bliss (Tsui Yuri ~Okaa-san ni wa Naisho da yo~)', 'The Eden of Grisaia', 'The Fruit of Grisaia', 'The Labyrinth of Grisaia']\n",
    "    #Narrator, Narraition라는 name 존재\n",
    "case_9 = ['CrossChannel']\n",
    "    #나레이션 태그 없음, 『』존재, 나레이션 태그가 효과음과 동작을 나타냄.\n",
    "case_10 = ['Dies Irae - Acta Est Fabula']\n",
    "    #[] 안에 존재하는 내용 제거. ()제거\n",
    "case_11 = ['Doki Doki Literature Club']\n",
    "    #{i} ~{/i} 안의 내용 제거, {}안의 내용 제거\n",
    "case_12 = ['DRACU-RIOT!']\n",
    "    #%32, %36, %0 존재\n",
    "case_13 = ['Driven Affairs']\n",
    "    #-GASP 존재\n",
    "case_14 = ['Everlasting Summer']\n",
    "    #<>안의 내용 제거\n",
    "case_15 = ['Fxxx Me Royally!! Horny Magical Princess (Himetai)']\n",
    "    # []()【】 안의 내용 제거\n",
    "case_16 = ['Kinkoi - Golden Loveriche (Kin\\'iro Loveriche)']\n",
    "    #<I> ~ </i> 안의 내용 제거, _ 제거\n",
    "case_17 = ['Libra of the Vampire Princess (Kyuuketsuki no Libra)']\n",
    "    #대화 안에 * 존재\n",
    "case_18 = ['Muv Luv Extra' '*Muv Luv Unlimited']\n",
    "    #문장안에 **, *──* 존재하면 문장 제거\n",
    "case_19 = ['Rewrite']\n",
    "    #나레이션 태그 없음, *snip*과 *chink* 존재\n",
    "case_20 = ['Waifu Hub']\n",
    "    #*( ~ )* 안의 내용 제거\n",
    "case_21 = ['Wolf Tails']\n",
    "    #{i} ~ {/i} 안의 내용 제거, [player_name] you로 변경, *()* 눈 you 태그로 변경, You를 you로 변경\n",
    "case_22 = ['Shikkoku no Sharnoth ~What a beautiful tomorrow~', 'Euphoria', 'Girls Frontline (Extras)', 'Girls Frontline', 'MonsterGirlQuest']\n",
    "    #제외\n",
    "case_23 = ['Dawn Of Malice', 'Love At First Sight', 'Academy34', 'Dawn Of Malice', 'Doki Doki Literature Club', 'Prince Of Suburbia', 'REFLEXIA Prototype ver', 'Sugar Style', 'Waifu Hub']\n",
    "    #YOU, you, user, <USER>를 you로 변경+\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exception(gmark, novel_content):\n",
    "    title = gmark.get_novel_title()\n",
    "    if title in case_1:\n",
    "        case_1_func(gmark, novel_content)\n",
    "    elif title in case_2:\n",
    "        case_2_func(gmark, novel_content)\n",
    "    elif title in case_3:\n",
    "        case_3_func(gmark, novel_content)\n",
    "    elif title in case_4:\n",
    "        case_4_func(gmark, novel_content)\n",
    "    elif title in case_5:\n",
    "        case_5_func(gmark, novel_content)\n",
    "    elif title in case_6:\n",
    "        case_6_func(gmark, novel_content)\n",
    "    elif title in case_7:\n",
    "        case_7_func(gmark, novel_content)\n",
    "    elif title in case_8:\n",
    "        case_8_func(gmark, novel_content)\n",
    "    elif title in case_9:\n",
    "        case_9_func(gmark, novel_content)\n",
    "    elif title in case_10:\n",
    "        case_10_func(gmark, novel_content)\n",
    "    elif title in case_11:\n",
    "        case_11_func(gmark, novel_content)\n",
    "    elif title in case_12:\n",
    "        case_12_func(gmark, novel_content)\n",
    "    elif title in case_14:\n",
    "        case_14_func(gmark, novel_content)\n",
    "    elif title in case_15:\n",
    "        case_15_func(gmark, novel_content)\n",
    "    elif title in case_16:\n",
    "        case_16_func(gmark, novel_content)\n",
    "    elif title in case_17:\n",
    "        case_17_func(gmark, novel_content)\n",
    "    elif title in case_18:\n",
    "        case_18_func(gmark, novel_content)\n",
    "    elif title in case_19:\n",
    "        case_19_func(gmark, novel_content)\n",
    "    elif title in case_20:\n",
    "        case_20_func(gmark, novel_content)\n",
    "    elif title in case_21:\n",
    "        case_21_func(gmark, novel_content)\n",
    "    elif title in case_22:\n",
    "        case_22_func(gmark, novel_content)\n",
    "    elif title in case_23:\n",
    "        case_23_func(gmark, novel_content)\n",
    "    else:\n",
    "        save(gmark, novel_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def custom_serializer(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return str(obj)  # 클래스의 __str__ 메서드를 사용하여 문자열로 변환\n",
    "    raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")\n",
    "\n",
    "def save_novel(gmark):\n",
    "    gmark.add_idx()\n",
    "    train_data = conversion_to_trainData(gmark)\n",
    "    save_to_yaml(gmark.get_idx(), gmark.get_novel_title(), train_data.get_value('trainSet'))\n",
    "    save_to_txt(gmark.get_idx(), gmark.get_novel_title(), train_data.get_text())\n",
    "    gmark.reset_json_dict()\n",
    "\n",
    "def save_to_yaml(idx, novel_title, result):\n",
    "    idx = str(idx)\n",
    "    file_name = novel_title+\"_\"+str(idx)+\".json\"\n",
    "    create_folder(os.path.join(save_translation_novelJson_path, novel_title))\n",
    "    save_json_path = os.path.join(save_translation_novelJson_path, novel_title, file_name)\n",
    "    \n",
    "    with open(save_json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(result, f, default=custom_serializer, indent=4)\n",
    "def save_to_txt(idx, novel_title, result):\n",
    "    idx = str(idx)\n",
    "    file_name = novel_title+\"_\"+str(idx)+\".txt\"\n",
    "    create_folder(os.path.join(save_translation_novelTxt_path, novel_title))\n",
    "    save_txt_path = os.path.join(save_translation_novelTxt_path, novel_title, file_name)\n",
    "    \n",
    "    with open(save_txt_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:47: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:117: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:252: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:47: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:117: SyntaxWarning: invalid escape sequence '\\*'\n",
      "<>:252: SyntaxWarning: invalid escape sequence '\\*'\n",
      "C:\\Users\\kimbo\\AppData\\Local\\Temp\\ipykernel_2812\\2630751606.py:47: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  qeustion_marker('narration', sentence.strip(\" \\\"\\'\\*\"), gmark)\n",
      "C:\\Users\\kimbo\\AppData\\Local\\Temp\\ipykernel_2812\\2630751606.py:117: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  qeustion_marker('narration', content.strip(\" \\\"\\'\\*\"), gmark)\n",
      "C:\\Users\\kimbo\\AppData\\Local\\Temp\\ipykernel_2812\\2630751606.py:252: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  qeustion_marker('user', content.strip(\" \\\"\\'\\*\"), gmark)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def save(gmark, novel_contents):\n",
    "    for sentence in novel_contents:\n",
    "        same_save_logic(gmark, sentence)\n",
    "    \n",
    "    if(gmark.get_json_dict_len()!=0):\n",
    "        save_novel(gmark)\n",
    "        \n",
    "def same_save_logic(gmark, sentence):\n",
    "    if sentence == \"\":\n",
    "        return\n",
    "    try:\n",
    "        if sentence[0] == \"*\":\n",
    "            qeustion_marker('narration', sentence.strip(\" \\\"\\'*\"), gmark)\n",
    "        elif sentence[0] == \"=\":\n",
    "            save_novel(gmark)\n",
    "        else:\n",
    "            name, content = sentence.split(\":\", 1)\n",
    "            qeustion_marker(name.strip(), content.strip(\" \\\"\\'*\"), gmark)\n",
    "    except:\n",
    "        qeustion_marker('narration', sentence.strip(\" \\\"\\'*\"), gmark)\n",
    "\n",
    "def del_smallBracket(sentence): # ( ) 소괄호\n",
    "    return re.sub(r\"\\(.*\\)\", \"\", sentence)\n",
    "def del_middleBracket(sentence): # [ ] 중괄호\n",
    "    return re.sub(r\"[.*]\", \"\", sentence)\n",
    "def del_lenrticularBracket(sentence): # 【 】 렌즈 괄호\n",
    "    return re.sub(r\"【.*】\", \"\", sentence) \n",
    "def del_bigBracket(sentence): # { } 대괄호\n",
    "    return re.sub(r\"{.*}\", \"\", sentence)\n",
    "def del_cornerBracket(sentence): # 『 』 겹낫표 \n",
    "    return re.sub(r\"『.*』\", \"\", sentence)\n",
    "def del_oneStar(sentence): # * 별표 한개\n",
    "    return re.sub(r\"\\*.*\\*\", \"\", sentence)\n",
    "def del_twoStar(sentence): # ** 별표 두개\n",
    "    return re.sub(r\"\\*\\*.*\\*\\*\", \"\", sentence)\n",
    "def del_specialSeparator(sentence): # <i> </i> 구분자\n",
    "    pattern = r\"<i>.*</i>|<i>.*<i>|<i>.*<I>|<i>.*</I>|<I>.*</i>\"\n",
    "    return re.sub(pattern, \"\", sentence)\n",
    "def del_angleBrackets(sentence): # < > 꺽쇠괄호\n",
    "    return re.sub(r\"<.*>\", \"\", sentence)\n",
    "\n",
    "def case_1_func(gmark, novel_contents): # \"TO:~ 로 시작하는 편지 존재\n",
    "    for sentence in novel_contents:\n",
    "        if \"To:\" in sentence:\n",
    "            qeustion_marker('narration', sentence.strip(\" \\\"\\'\\*\"), gmark)\n",
    "        else: \n",
    "            same_save_logic(gmark, sentence)\n",
    "    \n",
    "    if(gmark.get_json_dict_len()!=0):\n",
    "        save_novel(gmark)\n",
    "\n",
    "    \n",
    "def case_2_func(gmark, novel_contents): # 나레이션 태그 없음, * ~ * 안의 내용 제거\n",
    "    for sentence in novel_contents:\n",
    "        result = del_oneStar(sentence)\n",
    "        \n",
    "        same_save_logic(gmark, result)\n",
    "    \n",
    "    if(gmark.get_json_dict_len()!=0):\n",
    "        save_novel(gmark)\n",
    "        \n",
    "def case_3_func(gmark, novel_contents): # 나레이션 태그 안에*~* 안의 내용 제거\n",
    "    for sentence in novel_contents:\n",
    "        if sentence[0] == \"*\":\n",
    "            result = del_twoStar(sentence[1:-1])\n",
    "            same_save_logic(gmark, result)\n",
    "        else:    \n",
    "            same_save_logic(gmark, sentence)\n",
    "    \n",
    "    if(gmark.get_json_dict_len()!=0):\n",
    "        save_novel(gmark)\n",
    "    \n",
    "def case_4_func(gmark, novel_contents): # 나레이션 태그 없음, <i></i>, <i><i>, <i><I>,<i></I> 형태의 강조 태그 존재\n",
    "    for sentence in novel_contents:\n",
    "        \n",
    "        result = del_specialSeparator(sentence)\n",
    "                \n",
    "        same_save_logic(gmark, result)\n",
    "    \n",
    "    if(gmark.get_json_dict_len()!=0):\n",
    "        save_novel(gmark)\n",
    "        \n",
    "def case_5_func(gmark, novel_contents): # 대화문장 뒤 with dissolve존재, 대화 문장 내부에 {}, 언더바 존재\n",
    "    for sentence in novel_contents:\n",
    "        result = sentence.replace(\"with dissolve\", \"\")\n",
    "        result = result.replace(\"_\", \"\")\n",
    "        result = del_bigBracket(result)\n",
    "        \n",
    "        same_save_logic(gmark, result)\n",
    "    \n",
    "    if(gmark.get_json_dict_len()!=0):\n",
    "        save_novel(gmark)\n",
    "        \n",
    "def case_6_func(gmark, novel_contents): # {}, [] 존재\n",
    "    for sentence in novel_contents:\n",
    "        result = del_middleBracket(sentence)\n",
    "        result = del_bigBracket(result)\n",
    "        \n",
    "        same_save_logic(gmark, result)\n",
    "    \n",
    "    if(gmark.get_json_dict_len()!=0):\n",
    "        save_novel(gmark)\n",
    "        \n",
    "def case_7_func(gmark, novel_contents): # 나레이션 태그 없음\n",
    "    for sentence in novel_contents:\n",
    "        same_save_logic(gmark, sentence)\n",
    "    \n",
    "    if(gmark.get_json_dict_len()!=0):\n",
    "        save_novel(gmark)\n",
    "        \n",
    "def case_8_func(gmark, novel_contents): # Narrator, Narration라는 name 존재\n",
    "    for sentence in novel_contents:\n",
    "        if 'Narration' in sentence or 'Narrator' in sentence:\n",
    "            name, content = sentence.split(':',1)\n",
    "            qeustion_marker('narration', content.strip(\" \\\"\\'\\*\"), gmark)\n",
    "        else:\n",
    "            same_save_logic(gmark, sentence)\n",
    "    if(gmark.get_json_dict_len()!=0):\n",
    "        save_novel(gmark)\n",
    "        \n",
    "def case_9_func(gmark, novel_contents): # 나레이션 태그 없음, 『』존재, 나레이션 태그가 효과음과 동작을 나타냄.\n",
    "    for sentence in novel_contents:\n",
    "        result = del_cornerBracket(sentence)\n",
    "        \n",
    "        same_save_logic(gmark, result)\n",
    "    \n",
    "    if(gmark.get_json_dict_len()!=0):\n",
    "        save_novel(gmark)\n",
    "        \n",
    "def case_10_func(gmark, novel_contents): # [] 안에 존재하는 내용 제거. ( )제거\n",
    "    for sentence in novel_contents:\n",
    "        result = sentence.replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        result = del_middleBracket(result)\n",
    "        same_save_logic(gmark, result)\n",
    "    \n",
    "    if(gmark.get_json_dict_len()!=0):\n",
    "        save_novel(gmark)\n",
    "        \n",
    "def case_11_func(gmark, novel_contents): # {i} ~{/i} 안의 내용 제거, {}안의 내용 제거\n",
    "    for sentence in novel_contents:\n",
    "        result = del_specialSeparator(sentence)\n",
    "        result = del_bigBracket(result)\n",
    "        \n",
    "        same_save_logic(gmark, result)\n",
    "    \n",
    "    if(gmark.get_json_dict_len()!=0):\n",
    "        save_novel(gmark)\n",
    "        \n",
    "def case_12_func(gmark, novel_contents): # %32, %36, %0 존재, 나레이션 태그 사이에 * ~ * 존재(제거)\n",
    "    for sentence in novel_contents:\n",
    "        pattern = r\"%32|%36|%0\"\n",
    "        result = re.sub(pattern, \"\", sentence)\n",
    "        result = del_oneStar(result)\n",
    "        \n",
    "        same_save_logic(gmark, result)\n",
    "    \n",
    "    if(gmark.get_json_dict_len()!=0):\n",
    "        save_novel(gmark)\n",
    "        \n",
    "def case_14_func(gmark, novel_contents): # <>안의 내용 제거\n",
    "    for sentence in novel_contents:\n",
    "        result = del_angleBrackets(sentence)\n",
    "        \n",
    "        same_save_logic(gmark, result)\n",
    "    \n",
    "    if(gmark.get_json_dict_len()!=0):\n",
    "        save_novel(gmark)\n",
    "        \n",
    "def case_15_func(gmark, novel_contents): # []()【】 제거\n",
    "    for sentence in novel_contents:\n",
    "        result = del_smallBracket(sentence)\n",
    "        result = del_middleBracket(result)\n",
    "        result = del_lenrticularBracket(result)\n",
    "        \n",
    "        same_save_logic(gmark, result)\n",
    "    \n",
    "    if(gmark.get_json_dict_len()!=0):\n",
    "        save_novel(gmark)\n",
    "        \n",
    "def case_16_func(gmark, novel_contents): # <I> ~ </i> 안의 내용 제거, _ 제거\n",
    "    for sentence in novel_contents:\n",
    "        result = del_specialSeparator(sentence)\n",
    "        result = result.replace(\"_\", \"\")\n",
    "        same_save_logic(gmark, sentence)\n",
    "    \n",
    "    if(gmark.get_json_dict_len()!=0):\n",
    "        save_novel(gmark)\n",
    "        \n",
    "def case_17_func(gmark, novel_contents): # 대화 안에 * 존재\n",
    "    for sentence in novel_contents:\n",
    "        if sentence[0] != \"*\":\n",
    "            result = del_oneStar(sentence)\n",
    "            same_save_logic(gmark, result)    \n",
    "        else:\n",
    "            same_save_logic(gmark, sentence)\n",
    "    \n",
    "    if(gmark.get_json_dict_len()!=0):\n",
    "        save_novel(gmark)\n",
    "        \n",
    "def case_18_func(gmark, novel_contents): # 문장안에 * ~ * 제거, ─* 존재하면 문장 제거\n",
    "    for sentence in novel_contents:\n",
    "        if \"─*\" in sentence:\n",
    "            continue\n",
    "        if sentence[0] != \"*\":\n",
    "            result = del_oneStar(sentence)\n",
    "            same_save_logic(gmark, result)\n",
    "        else:\n",
    "            same_save_logic(gmark, sentence)\n",
    "        \n",
    "    if(gmark.get_json_dict_len()!=0):\n",
    "        save_novel(gmark)\n",
    "        \n",
    "def case_19_func(gmark, novel_contents): # 나레이션 태그 없음, *snip*과 *chink* 존재\n",
    "    for sentence in novel_contents:\n",
    "        if \"*snip*\" in sentence or \"*chink*\" in sentence:\n",
    "            continue\n",
    "        same_save_logic(gmark, sentence)\n",
    "    \n",
    "    if(gmark.get_json_dict_len()!=0):\n",
    "        save_novel(gmark)\n",
    "        \n",
    "def case_20_func(gmark, novel_contents): # *( ~ )* 안의 내용 제거\n",
    "    for sentence in novel_contents:\n",
    "        result = re.sub(r\"\\*\\(.*\\)\\*\", \"\", sentence)\n",
    "        same_save_logic(gmark, result)\n",
    "    \n",
    "    if(gmark.get_json_dict_len()!=0):\n",
    "        save_novel(gmark)\n",
    "        \n",
    "def case_21_func(gmark, novel_contents): # {i} ~ {/i} 안의 내용 제거, [player_name] you로 변경, *()* 눈 user 태그로 변경, You를 you로 변경\n",
    "    for sentence in novel_contents:\n",
    "        result = del_specialSeparator(sentence)\n",
    "        result = result.replace(\"[player_name]\", \"you\")\n",
    "        result = result.replace(\"You\", \"you\")\n",
    "        if \"*(\" in sentence:\n",
    "            result = result.replace(\"*(\", \"\").replace(\")*\", \"\")\n",
    "            qeustion_marker(\"user\", result.strip(\" \\\"\\'\"), gmark)\n",
    "        else:\n",
    "            same_save_logic(gmark, result)\n",
    "    \n",
    "    if(gmark.get_json_dict_len()!=0):\n",
    "        save_novel(gmark)\n",
    "        \n",
    "def case_22_func(gmark, novel_contents):\n",
    "    return\n",
    "def case_23_func(gmark, novel_contents):\n",
    "    for sentence in novel_contents:\n",
    "        if 'you:' in sentence[:5].strip().lower() or '<USER>' in sentence[:5].strip():\n",
    "            name, content = sentence.split(':',1)\n",
    "            qeustion_marker('user', content.strip(\" \\\"\\'\\*\"), gmark)\n",
    "            continue\n",
    "        same_save_logic(gmark, sentence)\n",
    "    \n",
    "    if(gmark.get_json_dict_len()!=0):\n",
    "        save_novel(gmark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def novel_convert_to_json(novel_title, novel_contents):\n",
    "    gmark = Gmark()\n",
    "    \n",
    "    novel_title = novel_title.strip('.txt')\n",
    "    gmark.set_novel_title(novel_title)\n",
    "    \n",
    "    exception(gmark, novel_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kimbo\\AppData\\Local\\Temp\\ipykernel_2812\\2630751606.py:47: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  qeustion_marker('narration', sentence.strip(\" \\\"\\'\\*\"), gmark)\n",
      "C:\\Users\\kimbo\\AppData\\Local\\Temp\\ipykernel_2812\\2630751606.py:117: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  qeustion_marker('narration', content.strip(\" \\\"\\'\\*\"), gmark)\n",
      "C:\\Users\\kimbo\\AppData\\Local\\Temp\\ipykernel_2812\\2630751606.py:252: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  qeustion_marker('user', content.strip(\" \\\"\\'\\*\"), gmark)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\kimbo\\\\code\\\\insight_text_game\\\\translation\\\\..\\\\dataset\\\\visual-novels-json-ko\\\\9-nine- Episode 1\\\\9-nine- Episode 1_1.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     11\u001b[0m f\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m---> 12\u001b[0m \u001b[43mnovel_convert_to_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnovel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnovel_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplete novel : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnovel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m, in \u001b[0;36mnovel_convert_to_json\u001b[1;34m(novel_title, novel_contents)\u001b[0m\n\u001b[0;32m      4\u001b[0m novel_title \u001b[38;5;241m=\u001b[39m novel_title\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m gmark\u001b[38;5;241m.\u001b[39mset_novel_title(novel_title)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mexception\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgmark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnovel_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 48\u001b[0m, in \u001b[0;36mexception\u001b[1;34m(gmark, novel_content)\u001b[0m\n\u001b[0;32m     46\u001b[0m     case_23_func(gmark, novel_content)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 48\u001b[0m     \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgmark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnovel_content\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m, in \u001b[0;36msave\u001b[1;34m(gmark, novel_contents)\u001b[0m\n\u001b[0;32m      5\u001b[0m     same_save_logic(gmark, sentence)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(gmark\u001b[38;5;241m.\u001b[39mget_json_dict_len()\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m----> 8\u001b[0m     \u001b[43msave_novel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgmark\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m, in \u001b[0;36msave_novel\u001b[1;34m(gmark)\u001b[0m\n\u001b[0;32m      9\u001b[0m gmark\u001b[38;5;241m.\u001b[39madd_idx()\n\u001b[0;32m     10\u001b[0m train_data \u001b[38;5;241m=\u001b[39m conversion_to_trainData(gmark)\n\u001b[1;32m---> 11\u001b[0m \u001b[43msave_to_yaml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgmark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_idx\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgmark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_novel_title\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrainSet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m save_to_txt(gmark\u001b[38;5;241m.\u001b[39mget_idx(), gmark\u001b[38;5;241m.\u001b[39mget_novel_title(), train_data\u001b[38;5;241m.\u001b[39mget_text())\n\u001b[0;32m     13\u001b[0m gmark\u001b[38;5;241m.\u001b[39mreset_json_dict()\n",
      "Cell \u001b[1;32mIn[12], line 20\u001b[0m, in \u001b[0;36msave_to_yaml\u001b[1;34m(idx, novel_title, result)\u001b[0m\n\u001b[0;32m     17\u001b[0m file_name \u001b[38;5;241m=\u001b[39m novel_title\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(idx)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     18\u001b[0m save_json_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_translation_novelJson_path, novel_title, file_name)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msave_json_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     21\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(result, f, default\u001b[38;5;241m=\u001b[39mcustom_serializer, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kimbo\\code\\insight_text_game\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\kimbo\\\\code\\\\insight_text_game\\\\translation\\\\..\\\\dataset\\\\visual-novels-json-ko\\\\9-nine- Episode 1\\\\9-nine- Episode 1_1.json'"
     ]
    }
   ],
   "source": [
    "for novel_name in novel_list:\n",
    "    open_file = os.path.join(novelSet_path, novel_name)\n",
    "    f = open(open_file, 'r', encoding='utf-8')\n",
    "    novel_content = []\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line: \n",
    "            break\n",
    "        novel_content.append(line.strip())\n",
    "        break\n",
    "    f.close()\n",
    "    novel_convert_to_json(novel_name, novel_content)\n",
    "    print(f'complete novel : {novel_name}')\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qeustion_marker"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
