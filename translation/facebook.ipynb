{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/facebook/mbart-large-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Monday has arrived, and my No Desire To Go To School-itis and Don't Wanna Get Out Of Bed-osis are both acting up.\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    "article_hi = \"Monday has arrived, and my No Desire To Go To School-itis and Don't Wanna Get Out Of Bed-osis are both acting up, but I muster up my willpower and get dressed.\"\n",
    "\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50\")\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50\")\n",
    "\n",
    "tokenizer.src_lang = \"en_XX\"\n",
    "encoded_hi = tokenizer(article_hi, return_tensors=\"pt\")\n",
    "generated_tokens = model.generate(\n",
    "    **encoded_hi,\n",
    "    forced_bos_token_id=tokenizer.lang_code_to_id[\"ko_KR\"]\n",
    ")\n",
    "tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\code\\insight_text_game\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2SeqLMOutput(loss=tensor(9.9719, grad_fn=<NllLossBackward0>), logits=tensor([[[ 5.9384e+01, -1.4623e+00,  3.7075e+01,  ...,  5.7301e+00,\n",
       "          -9.7913e-01,  1.5201e+01],\n",
       "         [ 5.9363e+01, -1.4596e+00,  3.6913e+01,  ...,  5.7274e+00,\n",
       "          -9.5642e-01,  1.5132e+01],\n",
       "         [ 1.0301e+01, -2.2472e-01,  1.5943e+01,  ..., -2.4285e+00,\n",
       "           1.6040e+00,  7.8643e+00],\n",
       "         ...,\n",
       "         [ 5.4041e-02, -2.3913e-01,  1.2515e+01,  ...,  3.2415e-01,\n",
       "           1.8379e+00,  5.7910e+00],\n",
       "         [ 2.5747e+00, -1.8596e-01,  9.4286e+00,  ...,  4.8606e-01,\n",
       "           1.5175e+00,  4.5009e+00],\n",
       "         [ 1.1467e+01, -4.1692e-01,  2.4934e+01,  ...,  3.0820e-01,\n",
       "           1.2864e+00,  1.1943e+01]]], grad_fn=<AddBackward0>), past_key_values=None, decoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=tensor([[[ 0.0204,  0.0117, -0.0101,  ..., -0.0427, -0.0093,  0.0264],\n",
       "         [-0.8181,  0.4772, -0.7508,  ..., -1.2650,  0.7026, -0.2295],\n",
       "         [ 0.1505,  0.2078, -0.9662,  ...,  0.1658, -0.1332,  0.7731],\n",
       "         ...,\n",
       "         [-0.4763,  0.1606, -0.6151,  ..., -0.1997, -1.3798,  0.5627],\n",
       "         [ 0.0806,  0.4624, -0.2502,  ..., -0.3803, -0.9475, -0.3394],\n",
       "         [ 0.0099, -0.0030, -0.0053,  ..., -0.0162,  0.0076, -0.0081]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), encoder_hidden_states=None, encoder_attentions=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50\")\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50\", src_lang=\"en_XX\", tgt_lang=\"ko_KR\")\n",
    "\n",
    "src_text = \"Monday has arrived, and my No Desire To Go To School-itis and Don't Wanna Get Out Of Bed-osis are both acting up, but I muster up my willpower and get dressed.\"\n",
    "tgt_text =  \"월요일이 다가왔고, '학교 가고 싶지 않아'와 '침대에서 벗어나고 싶지 않아'가 모두 행동하고 있지만, 나는 의지를 내서 옷을 입는다.\"\n",
    "\n",
    "model_inputs = tokenizer(src_text, return_tensors=\"pt\")\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    labels = tokenizer(tgt_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "model(**model_inputs, labels=labels) # forward pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['월요일이 왔습니다. 학교에 가지 않겠다는 저의 소망과 침대에서 빠져나오지 않겠다는 저의 소망은 둘 다 움직입니다. 하지만 저는 제 의지력을 모아 옷을 입습니다.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    "article_hi = \"Monday has arrived, and my No Desire To Go To School-itis and Don't Wanna Get Out Of Bed-osis are both acting up, but I muster up my willpower and get dressed.\"\n",
    "\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "\n",
    "tokenizer.src_lang = \"en_XX\"\n",
    "encoded_hi = tokenizer(article_hi, return_tensors=\"pt\")\n",
    "generated_tokens = model.generate(\n",
    "    **encoded_hi,\n",
    "    forced_bos_token_id=tokenizer.lang_code_to_id[\"ko_KR\"]\n",
    ")\n",
    "tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
